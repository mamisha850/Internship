{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99852c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07269f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import pandas as pd\n",
    " \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e3b59eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job opportunity For Data Analyst at Trellance ...</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>CURise Analytics Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                           Sr.Business Data Analyst   \n",
       "1                                    Sr Data Analyst   \n",
       "2                       Senior Data Analysis Analyst   \n",
       "3  Job opportunity For Data Analyst at Trellance ...   \n",
       "4                                       Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6            Master Data Management Business Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                             Associate Data Analyst   \n",
       "9                             Associate Data Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "3                     Bangalore/Bengaluru, Ahmedabad   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5               Bangalore/Bengaluru(Old Madras Road)   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                 Company_name Experience_required  \n",
       "0                   Collabera            6-11 Yrs  \n",
       "1             Thomson Reuters             5-8 Yrs  \n",
       "2                       Capco            7-12 Yrs  \n",
       "3  CURise Analytics Pvt. Ltd.             0-2 Yrs  \n",
       "4             Thomson Reuters             2-3 Yrs  \n",
       "5                    KrazyBee             3-6 Yrs  \n",
       "6                   Accenture             6-8 Yrs  \n",
       "7                       Wipro             4-9 Yrs  \n",
       "8                       Optum             2-7 Yrs  \n",
       "9                       Optum             1-4 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques1.\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "search_location = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "search_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "# Scrap the data \n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "title=[]\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "job_title=title[0:10]\n",
    "\n",
    "loc_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "location_title=loc[0:10]\n",
    "\n",
    "comp_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "comp_name=[]\n",
    "for i in comp_tags:\n",
    "    comp_name.append(i.text)\n",
    "comp_title=comp_name[0:10]\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp=[]\n",
    "for i in exp_tag:\n",
    "    exp.append(i.text)\n",
    "exp_title=exp[0:10]\n",
    "\n",
    "Data_Analyst=pd.DataFrame({'Job_title':job_title,'Job_location':location_title,'Company_name':comp_title,\n",
    "                           'Experience_required':exp_title})\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c37535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Gurgaon/Gurugram, C...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0              Data Scientist/ Senior Data Scientist   \n",
       "1  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "2                   Hiring For Senior Data Scientist   \n",
       "3                                 Dataiku Consultant   \n",
       "4                                     Data Scientist   \n",
       "5  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "6                 Data Scientist: Advanced Analytics   \n",
       "7                                 Research Scientist   \n",
       "8                         Principal - Data Scientist   \n",
       "9            Research and Development -AI/ML -(PhD )   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Pune, Gurgaon/Gurugram, C...   \n",
       "1  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "2                          Bangalore/Bengaluru, Pune   \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "\n",
       "                      Company_name  \n",
       "0                Fractal Analytics  \n",
       "1                            Wipro  \n",
       "2  TATA CONSULTANCY SERVICES (TCS)  \n",
       "3                            Wipro  \n",
       "4                Applied Materials  \n",
       "5                              PwC  \n",
       "6                              IBM  \n",
       "7                              IBM  \n",
       "8               Schneider Electric  \n",
       "9                              EXL  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques2\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Enter the data\n",
    "\n",
    "scrap_job = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "scrap_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "scrap_location = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "scrap_location.send_keys(\"Bangalore\")\n",
    "\n",
    "scrap_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "scrap_button.click()\n",
    "\n",
    "# Filter the data\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "title=[]\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "job_title=title[0:10]\n",
    "\n",
    "loc_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "location_title=loc[0:10]\n",
    "\n",
    "comp_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "comp_name=[]\n",
    "for i in comp_tags:\n",
    "    comp_name.append(i.text)\n",
    "comp_title=comp_name[0:10]\n",
    "\n",
    "Data_Scientist=pd.DataFrame({'Job_title':job_title,'Job_location':location_title,'Company_name':comp_title})\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbaa8990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job_title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1             Senior Associate - Data Science   \n",
       "2            Data Scientist - Noida/Bangalore   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5        Data Scientist - Machine learning AI   \n",
       "6              Data Scientist - MIND Infotech   \n",
       "7           Data Scientist - Engine Algorithm   \n",
       "8                    Knowledge/Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...   \n",
       "6                                              Noida   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                        Delhi / NCR   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_name Experience_required  \n",
       "0                   Boston Consulting Group                2-5   \n",
       "1                              Black Turtle                4-7   \n",
       "2                                       EXL               5-10   \n",
       "3                 8KMiles Software Services                2-7   \n",
       "4                 8KMiles Software Services                2-7   \n",
       "5                             Teq Analytics                3-8   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED                4-8   \n",
       "7                              Primo Hiring                1-3   \n",
       "8                   BOLD Technology Systems                3-6   \n",
       "9   Mount Talent Consulting Private Limited                2-4   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques3\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='http://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "# Filter the location and salary\n",
    "\n",
    "filter_loc = driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i')\n",
    "filter_loc.click()\n",
    "\n",
    "filter_salary = driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "filter_salary.click()\n",
    "\n",
    "# Scrap the data\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "title=[]\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "job_title=title[0:10]\n",
    "\n",
    "loc_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "location_title=loc[0:10]\n",
    "\n",
    "comp_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "comp_name=[]\n",
    "for i in comp_tags:\n",
    "    comp_name.append(i.text)\n",
    "comp_title=comp_name[0:10]\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp=[]\n",
    "for i in exp_tag:\n",
    "    exp.append(i.text.replace('Yrs',''))\n",
    "exp_title=exp[0:10]\n",
    "\n",
    "Data_Scientist=pd.DataFrame({'Job_title':job_title,'Job_location':location_title,'Company_name':comp_title,\n",
    "                           'Experience_required':exp_title})\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques4.\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='http://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Search sunglasses\n",
    "search_detail=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_detail.send_keys(\"Sunglasses\")\n",
    "\n",
    "search_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg')\n",
    "search_icon.click()\n",
    "\n",
    "# Scrap data\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "b=[]\n",
    "for i in brand_tags:\n",
    "    b.append(i.text)\n",
    "    \n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "p=[]\n",
    "for i in product_tags:\n",
    "    p.append(i.text)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "pr=[]\n",
    "for i in price_tags:\n",
    "    pr.append(i.text)\n",
    "\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "off=[]\n",
    "for i in Offer_tags:\n",
    "    off.append(i.text.replace('% off',''))\n",
    "    \n",
    "z=(len(b),len(p),len(pr),len(off))\n",
    "\n",
    "#Click Next\n",
    "\n",
    "Next_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "Next_icon.click()\n",
    "\n",
    "#For next data\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "b1=[]\n",
    "p1=[]\n",
    "pr1=[]\n",
    "off1=[]\n",
    "\n",
    "for i in brand_tags:\n",
    "    b1.append(i.text)\n",
    "\n",
    "for i in product_tags:\n",
    "    p1.append(i.text)\n",
    "    \n",
    "for i in price_tags:\n",
    "    pr1.append(i.text)   \n",
    "    \n",
    "for i in Offer_tags:\n",
    "    off1.append(i.text)\n",
    "\n",
    "z=(len(b1),len(p1),len(pr1),len(off1))\n",
    "    \n",
    "# Again click Next\n",
    "\n",
    "Next_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "Next_icon.click()\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@cclass=\"_30jeq3\"]')\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "b2=[]\n",
    "p2=[]\n",
    "pr2=[]\n",
    "off2=[]\n",
    "\n",
    "for i in brand_tags:\n",
    "    b2.append(i.text)\n",
    "\n",
    "for i in product_tags:\n",
    "    p2.append(i.text)\n",
    "    \n",
    "for i in price_tags:\n",
    "    pr2.append(i.text)   \n",
    "    \n",
    "for i in Offer_tags:\n",
    "    off2.append(i.text)\n",
    "    \n",
    "br = b2[:20]   \n",
    "pro = p2[:20]\n",
    "pri = pr2[:20]\n",
    "offe = off2[:20]\n",
    "\n",
    "brand=b+b1+br\n",
    "product=p+p1+pro\n",
    "price=pr+pr1+pri\n",
    "offer=off+off1+offe\n",
    "\n",
    "length=(len(brand),len(product),len(price),len(offer))\n",
    "\n",
    "Sunglasses=pd.DataFrame({'Brand':brand,'Product':product,'Price':price,'Price_offer':offer})\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques6.\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Search sneakers\n",
    "search_detail=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_detail.send_keys(\"sneakers\")\n",
    "\n",
    "search_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg')\n",
    "search_icon.click()\n",
    "\n",
    "# For first scraping\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "br=[]\n",
    "pro=[]\n",
    "pr=[]\n",
    "of=[]\n",
    "\n",
    "for i in brand_tags:\n",
    "    br.append(i.text)    \n",
    "\n",
    "for i in product_tags:\n",
    "    pro.append(i.text)\n",
    "    \n",
    "for i in price_tags:\n",
    "    pr.append(i.text)   \n",
    "    \n",
    "for i in Offer_tags:\n",
    "    of.append(i.text.replace('% off',''))    \n",
    "    \n",
    "brn=br[0:38] \n",
    "pri=pr[0:38]\n",
    "off=of[0:38]\n",
    "\n",
    "# Click on Next\n",
    "Next_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "Next_icon.click()\n",
    "\n",
    "# For second scraping\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "br1=[]\n",
    "pro1=[]\n",
    "pr1=[]\n",
    "of1=[]\n",
    "\n",
    "for i in brand_tags:\n",
    "    br1.append(i.text)\n",
    "\n",
    "for i in product_tags:\n",
    "    pro1.append(i.text)\n",
    "    \n",
    "for i in price_tags:\n",
    "    pr1.append(i.text)   \n",
    "    \n",
    "for i in Offer_tags:\n",
    "    of1.append(i.text.replace('% off',''))\n",
    "   \n",
    "    \n",
    "brn1=br1[0:34] \n",
    "pri1=pr1[0:34]\n",
    "off1=of1[0:34]\n",
    "\n",
    "# Click on Next\n",
    "Next_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "Next_icon.click()\n",
    "\n",
    "# For third searching\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "Offer_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "br2=[]\n",
    "pro2=[]\n",
    "pr2=[]\n",
    "of2=[]\n",
    "\n",
    "for i in brand_tags:\n",
    "    br2.append(i.text)\n",
    "\n",
    "for i in product_tags:\n",
    "    pro2.append(i.text)\n",
    "    \n",
    "for i in price_tags:\n",
    "    pr2.append(i.text)   \n",
    "    \n",
    "for i in Offer_tags:\n",
    "    of2.append(i.text.replace('% off',''))\n",
    "    \n",
    "brnd = br2[:28]   \n",
    "prod = pro2[:28]\n",
    "pric = pr2[:28]\n",
    "offe = of2[:28]\n",
    "\n",
    "# combine all \n",
    "brand=brn+brn1+brnd\n",
    "product=pro+pro1+prod\n",
    "price=pri+pri1+pric\n",
    "offer=off+off1+offe\n",
    "\n",
    "# Check length\n",
    "length=(len(brand),len(product),len(price),len(offer))\n",
    "\n",
    "sneakers=pd.DataFrame({'Brand':brand,'Product':product,'Price':price,'Offer':offer})\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269438e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques8.\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)\n",
    "\n",
    "# Search Laptop\n",
    "\n",
    "search_title = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search_title.send_keys(\"Laptop\")\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_button.click()\n",
    "\n",
    "# Filter intel core i7\n",
    "\n",
    "corei7=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[2]/li[13]/span/a/div/label/i')\n",
    "corei7.click()\n",
    "\n",
    "# Scrap Title, Rating, Price\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none s-padding-right-small s-title-instructions-style\"]')\n",
    "t=[]\n",
    "for i in title_tag:\n",
    "    t.append(i.text)\n",
    "\n",
    "title=t[:10]\n",
    "\n",
    "rate_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]')\n",
    "r=[]\n",
    "for i in rate_tag:\n",
    "    r.append(i.text)\n",
    "rate=r[:10]\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "p=[]\n",
    "for i in price_tag:\n",
    "    p.append(i.text)\n",
    "price=p[:10]\n",
    "\n",
    "Laptop=pd.DataFrame({'Title':title,'Rate':rate,'Price':price})\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques9.\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Dell\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "jobs_section = driver.find_element(By.XPATH,'/html/body/div[1]/nav/nav/a[6]')\n",
    "jobs_section.click()\n",
    "\n",
    "# Enter the Data Scientist in skill and then search\n",
    "\n",
    "title_detail = driver.find_element(By.NAME,\"ab_jobsSearch\")\n",
    "title_detail.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span')\n",
    "search_button.click()\n",
    "\n",
    "# Click on location then Enter Noida in location and last select Noida\n",
    "\n",
    "loc_button = driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "loc_button.click()\n",
    "\n",
    "loc_detail = driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "loc_detail.send_keys(\"Noida\")\n",
    "\n",
    "select_loc =  driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "select_loc.click()\n",
    "\n",
    "# Scrap the details\n",
    "\n",
    "comp_tags=driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "comp_name=[]\n",
    "for i in comp_tags:\n",
    "    comp_name.append(i.text)\n",
    "    \n",
    "desg_tags=driver.find_elements(By.XPATH,'//a[@class=\"title noclick\"]')\n",
    "designation=[]\n",
    "for i in desg_tags:\n",
    "    designation.append(i.text)  \n",
    "    \n",
    "rate_tags=driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "rate=[]\n",
    "for i in rate_tags:\n",
    "    rate.append(i.text)\n",
    "    \n",
    "exp_tags=driver.find_elements(By.XPATH,'//div[@class=\"job-basic-info show-flex\"]')\n",
    "e=[]\n",
    "for i in exp_tags:\n",
    "    e.append(i.text.split()[0])\n",
    "exp_req=e[1:11]        \n",
    "\n",
    "Data_Scientist=pd.DataFrame({'Company Name':comp_name,'Designation':designation,'Rating':rate,'Experience':exp_req})\n",
    "Data_Scientist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
