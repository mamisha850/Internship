{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9285225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0460df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c2e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of header tags: \n",
      "\n",
      " [<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\">Main Page</h1>, <h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>] \n",
      "\n",
      " [<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>, <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>, <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>, <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>, <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>, <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>, <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>, <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>, <h2>Navigation menu</h2>] \n",
      "\n",
      " [<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>, <h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>, <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ques1. Program to display all header tags from wikipedia.org\n",
    "\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "hd1= soup.find_all('h1')\n",
    "hd2= soup.find_all('h2')\n",
    "hd3= soup.find_all('h3')\n",
    "\n",
    "    \n",
    "print(\"List of header tags: \\n\\n\",hd1,\"\\n\\n\",hd2,\"\\n\\n\",hd3,\"\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdea7caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of releasing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption(1994)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Lord of the Rings: The Return of the Kin...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Schindler's List(1993)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Drishyam(2013)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Jagten(2012)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Jodaeiye Nader az Simin(2011)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Incendies(2010)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Spider-Man: No Way Home(2021)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Names Ratings  \\\n",
       "0                    1.The Shawshank Redemption(1994)     9.3   \n",
       "1                               2.The Godfather(1972)     9.2   \n",
       "2                             3.The Dark Knight(2008)     9.0   \n",
       "3   4.The Lord of the Rings: The Return of the Kin...     9.0   \n",
       "4                            5.Schindler's List(1993)     9.0   \n",
       "..                                                ...     ...   \n",
       "95                                  96.Drishyam(2013)     8.3   \n",
       "96                                    97.Jagten(2012)     8.3   \n",
       "97                   98.Jodaeiye Nader az Simin(2011)     8.3   \n",
       "98                                 99.Incendies(2010)     8.3   \n",
       "99                  100.Spider-Man: No Way Home(2021)     8.3   \n",
       "\n",
       "   Year of releasing  \n",
       "0             (1994)  \n",
       "1             (1972)  \n",
       "2             (2008)  \n",
       "3             (2003)  \n",
       "4             (1993)  \n",
       "..               ...  \n",
       "95            (2013)  \n",
       "96            (2012)  \n",
       "97            (2011)  \n",
       "98            (2010)  \n",
       "99            (2021)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques2. Program to display IMDB's top rated 100 movies\n",
    "\n",
    "\n",
    "page = requests.get('https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "names = []\n",
    "rates = []\n",
    "years = []\n",
    "\n",
    "for i in soup('h3',class_=\"lister-item-header\"):\n",
    "    names.append(i.text.replace('\\n',''))\n",
    "    \n",
    "for i in soup('div',class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rates.append(i.text.replace('\\n',''))\n",
    "        \n",
    "for i in soup('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    years.append(i.text.replace('I',''))\n",
    "        \n",
    "Top_movies = pd.DataFrame({\"Names\":names,\"Ratings\":rates,\"Year of releasing\":years})\n",
    "Top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa07c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Jai Bhim(2021)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Anbe Sivam(2003)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Golmaal(1979)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Nayakan(1987)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      Pariyerum Perumal(2018)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Masaan(2015)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      Kahaani(2012)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Baahubali 2: The Conclusion(2017)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Dil Chahta Hai(2001)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Maheshinte Prathikaaram(2016)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Rating Year of release\n",
       "0                             1.      Jai Bhim(2021)    8.4          (2021)\n",
       "1                           2.      Anbe Sivam(2003)    8.4          (2003)\n",
       "2                              3.      Golmaal(1979)    8.4          (1979)\n",
       "3                              4.      Nayakan(1987)    8.4          (1987)\n",
       "4                    5.      Pariyerum Perumal(2018)    8.4          (2018)\n",
       "..                                               ...    ...             ...\n",
       "95                             96.      Masaan(2015)    8.0          (2015)\n",
       "96                            97.      Kahaani(2012)    8.0          (2012)\n",
       "97        98.      Baahubali 2: The Conclusion(2017)    8.0          (2017)\n",
       "98                     99.      Dil Chahta Hai(2001)    8.0          (2001)\n",
       "99           100.      Maheshinte Prathikaaram(2016)    8.0          (2016)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques3. Program to display IMDB's top rated 100 Indian movies\n",
    "\n",
    "\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "n= []\n",
    "r= []\n",
    "y= []\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    n.append(i.text.replace('\\n',''))\n",
    "    \n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    r.append(i.text.replace('\\n',''))  \n",
    "    \n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    y.append(i.text)    \n",
    "    \n",
    "name=n[:100]\n",
    "rate=r[:100]\n",
    "year=y[:100]\n",
    "\n",
    "Top_Indian_movies = pd.DataFrame({\"Name\":name,\"Rating\":rate,\"Year of release\":year})\n",
    "Top_Indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035da4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Pranab Mukherjee (1935-2020)Term of Office: 25 July, 2012 to 25 July, 2017 http://pranabmukherjee.nic.in',\n",
       " 'Smt Pratibha Devisingh Patil (birth - 1934)Term of Office: 25 July, 2007 to 25 July, 2012 http://pratibhapatil.nic.in',\n",
       " 'DR. A.P.J. Abdul Kalam (1931-2015)Term of Office: 25 July, 2002 to 25 July, 2007 http://abdulkalam.nic.in',\n",
       " 'Shri K. R. Narayanan (1920 - 2005)Term of Office: 25 July, 1997 to 25 July, 2002 ',\n",
       " 'Dr Shankar Dayal Sharma (1918-1999)Term of Office: 25 July, 1992 to 25 July, 1997 ',\n",
       " 'Shri R Venkataraman (1910-2009)Term of Office: 25 July, 1987 to 25 July, 1992 ',\n",
       " 'Giani Zail Singh (1916-1994)Term of Office: 25 July, 1982 to 25 July, 1987 ',\n",
       " 'Shri Neelam Sanjiva Reddy (1913-1996)Term of Office: 25 July, 1977 to 25 July, 1982 ',\n",
       " 'Dr. Fakhruddin Ali Ahmed (1905-1977)Term of Office: 24 August, 1974 to 11 February, 1977',\n",
       " 'Shri Varahagiri Venkata Giri (1894-1980)Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " 'Dr. Zakir Husain (1897-1969)Term of Office: 13 May, 1967 to 3 May, 1969',\n",
       " 'Dr. Sarvepalli Radhakrishnan (1888-1975)Term of Office: 13 May, 1962 to 13 May, 1967',\n",
       " 'Dr. Rajendra Prasad (1884-1963) Term of Office: 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques4. Program to display the list of respected former presidents of India\n",
    "\n",
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "detail = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    detail.append(i.text.replace('\\n',''))\n",
    "    \n",
    "detail  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7412993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match[0]: 12\n",
      "point[0]: 1,505\n",
      "rate[0]:                             125                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>12</td>\n",
       "      <td>1505</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>22</td>\n",
       "      <td>2,756</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>22</td>\n",
       "      <td>2,304</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,872</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,275</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>32</td>\n",
       "      <td>2,306</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Rating\n",
       "0   New Zealand      12   1505    8.4\n",
       "1       England      22  2,756    8.4\n",
       "2      Pakistan      19  2,005    8.4\n",
       "3         India      22  2,304    8.4\n",
       "4     Australia      23  2,325    8.4\n",
       "5  South Africa      19  1,872    8.3\n",
       "6    Bangladesh      24  2,275    8.3\n",
       "7     Sri Lanka      29  2,658    8.3\n",
       "8   West Indies      32  2,306    8.3\n",
       "9   Afghanistan      18  1,238    8.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques5. Program to scrape men's cricket ranking from icc-cricket.com\n",
    "# (i) Top 10 ODI teams\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "t = []\n",
    "m = []\n",
    "p = []\n",
    "ra = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    t.append(i.text)\n",
    "    \n",
    "x=soup.find('td',class_=\"rankings-block__banner--matches\")    \n",
    "y=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    m.append(i.text)\n",
    "    \n",
    "z=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\") \n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    ra.append(i.text)\n",
    "\n",
    "teams=t[:10]\n",
    "print(\"match[0]:\",x.text)\n",
    "print(\"point[0]:\",y.text)\n",
    "match=m[:18:2]\n",
    "match.insert(0,12)\n",
    "point=m[1:18:2]\n",
    "point.insert(0,1505)\n",
    "print(\"rate[0]:\",z.text.replace('\\n',''))\n",
    "ra.insert(0,125)\n",
    "rate=r[:10]\n",
    "\n",
    "ODI_Team = pd.DataFrame({\"Teams\":teams,\"Matches\":match,\"Points\":point,\"Rating\":rate})\n",
    "ODI_Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c0c642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names[0]: Babar Azam\n",
      "teams[0]: PAK\n",
      "rates[0]: 892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Batsmen Team Rating\n",
       "0             Babar Azam  PAK    892\n",
       "1            Imam-ul-Haq  PAK    815\n",
       "2            Virat Kohli  IND    811\n",
       "3           Rohit Sharma  IND    791\n",
       "4        Quinton de Kock   SA    789\n",
       "5            Ross Taylor   NZ    775\n",
       "6  Rassie van der Dussen   SA    769\n",
       "7         Jonny Bairstow  ENG    760\n",
       "8           David Warner  AUS    745\n",
       "9            Aaron Finch  AUS    727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques5. Program to scrape men's cricket ranking from icc-cricket.com\n",
    "# (ii) Top 10 ODI Batsmen\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "n=[]\n",
    "nm=[]\n",
    "tm=[]\n",
    "ra=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    n.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    nm.append(i.text.replace('\\n',''))\n",
    "    \n",
    "q=soup.find('div',class_=\"rankings-block__banner--nationality\")    \n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    tm.append(i.text)  \n",
    "    \n",
    "r=soup.find('div',class_=\"rankings-block__banner--rating\")    \n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    ra.append(i.text)\n",
    "    \n",
    "naam=n[0]\n",
    "print(\"names[0]:\",naam)\n",
    "names=nm[0:9]\n",
    "names.insert(0,'Babar Azam')\n",
    "print(\"teams[0]:\",q.text.split()[0].replace('\\n',''))\n",
    "teams=tm[0:9]\n",
    "teams.insert(0,'PAK')\n",
    "print(\"rates[0]:\",r.text)\n",
    "rates=ra[0:9]\n",
    "rates.insert(0,892)\n",
    "\n",
    "ODI_batsmen= pd.DataFrame({\"Batsmen\":names,\"Team\":teams,\"Rating\":rates})\n",
    "ODI_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3e7e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name[0]: Trent Boult\n",
      "team[0]: \n",
      "\n",
      "NZ\n",
      "                            726\n",
      "\n",
      "rate[0]: 726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bowler Team Rating\n",
       "0       Trent Boult   NZ    726\n",
       "1      Chris Woakes  ENG    686\n",
       "2        Matt Henry   NZ    683\n",
       "3    Shaheen Afridi  PAK    681\n",
       "4    Jasprit Bumrah  IND    679\n",
       "5  Mujeeb Ur Rahman  AFG    676\n",
       "6    Josh Hazlewood  AUS    667\n",
       "7      Mehedi Hasan  BAN    661\n",
       "8     Mohammad Nabi  AFG    657\n",
       "9   Shakib Al Hasan  BAN    657"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques5. Program to scrape men's cricket ranking from icc-cricket.com\n",
    "# (iii) Top 10 ODI Bowlers\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "v=[]\n",
    "bowler=[]\n",
    "w=[]\n",
    "te=[]\n",
    "s=[]\n",
    "re=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    v.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    bowler.append(i.text.replace('\\n',''))    \n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    w.append(i.text)\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    te.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    s.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    re.append(i.text)    \n",
    "    \n",
    "vm=v[1]\n",
    "print(\"name[0]:\",vm)\n",
    "bowler_names=bowler[9:18]\n",
    "bowler_names.insert(0,'Trent Boult')\n",
    "wm=w[1]\n",
    "print(\"team[0]:\",wm)\n",
    "teamms=te[9:18]\n",
    "teamms.insert(0,'NZ')\n",
    "sw=s[1]\n",
    "print(\"rate[0]:\",sw)\n",
    "ratees=re[9:18]\n",
    "ratees.insert(0,726)\n",
    "\n",
    "ODI_batsmen= pd.DataFrame({\"Bowler\":bowler_names,\"Team\":teamms,\"Rating\":ratees})\n",
    "ODI_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e922252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches[0]: 29\n",
      "points[0]: 4,837\n",
      "rates[0]:                             167                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>1505</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>32</td>\n",
       "      <td>2,756</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>2,005</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>2,304</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>2,325</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>1,872</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>2,275</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>2,658</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>2,306</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>1,238</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Rating\n",
       "0     Australia      29   1505    167\n",
       "1  South Africa      32  2,756    123\n",
       "2       England      30  2,005    118\n",
       "3         India      29  2,304    100\n",
       "4   New Zealand      31  2,325     97\n",
       "5   West Indies      30  1,872     92\n",
       "6    Bangladesh      12  2,275     78\n",
       "7      Pakistan      30  2,658     65\n",
       "8     Sri Lanka       8  2,306     48\n",
       "9       Ireland       8  1,238     44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques6. Program to scrape women's cricket ranking from icc-cricket.com\n",
    "#(i) Top 10 ODI teams\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "t = []\n",
    "m = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    t.append(i.text)\n",
    "    \n",
    "xw=soup.find('td',class_=\"rankings-block__banner--matches\")    \n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    m.append(i.text)    \n",
    "\n",
    "yw=soup.find('td', class_=\"rankings-block__banner--points\")\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    p.append(i.text)\n",
    "\n",
    "zw=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    r.append(i.text)\n",
    "    \n",
    "teams=t[:10]\n",
    "print(\"matches[0]:\",xw.text)\n",
    "matches=m[0:18:2] \n",
    "matches.insert(0,29)\n",
    "print(\"points[0]:\",yw.text)\n",
    "points=p[1:18:2] \n",
    "points.insert(0,4837)\n",
    "print(\"rates[0]:\",zw.text.replace('\\n',''))\n",
    "rates=r[:9]\n",
    "rates.insert(0,167)\n",
    "\n",
    "ODI_team = pd.DataFrame({\"Teams\":teams,\"Matches\":matches,\"Points\":point,\"Rating\":rates})\n",
    "ODI_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ffce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names[0]: Alyssa Healy\n",
      "team[0]: AUS\n",
      "rates[0]: 785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name team Rating\n",
       "0       Alyssa Healy  AUS    785\n",
       "1     Natalie Sciver  ENG    750\n",
       "2        Beth Mooney  AUS    748\n",
       "3    Laura Wolvaardt   SA    713\n",
       "4        Meg Lanning  AUS    710\n",
       "5     Rachael Haynes  AUS    701\n",
       "6  Amy Satterthwaite   NZ    681\n",
       "7    Smriti Mandhana  IND    669\n",
       "8     Tammy Beaumont  ENG    659\n",
       "9       Ellyse Perry  AUS    642"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques6. Program to scrape women's cricket ranking from icc-cricket.com\n",
    "# (ii) Top 10 ODI Batsmen\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "a=[]\n",
    "nw=[]\n",
    "tw=[]\n",
    "rw=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    a.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    nw.append(i.text.replace('\\n',''))\n",
    "\n",
    "qw=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    tw.append(i.text)\n",
    "\n",
    "rt=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rw.append(i.text)\n",
    "\n",
    "name=a[0]\n",
    "print(\"names[0]:\",name)\n",
    "names=nw[0:9]\n",
    "names.insert(0,'Alyssa Healy')\n",
    "print(\"team[0]:\",qw.text.split()[0].replace('\\n',''))\n",
    "team=tw[0:9]\n",
    "team.insert(0,'AUS')\n",
    "print(\"rates[0]:\",rt.text)\n",
    "rates=rw[0:9]\n",
    "rates.insert(0,785)\n",
    "\n",
    "ODI_batsmen = pd.DataFrame({\"Name\":names,\"team\":team,\"Rating\":rates})\n",
    "ODI_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc37a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name[0]: Natalie Sciver\n",
      "teams[0]: ENG\n",
      "rate[0]: 393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sune Luus</td>\n",
       "      <td>SA</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name team Rating\n",
       "0    Natalie Sciver  ENG    393\n",
       "1      Ellyse Perry  AUS    374\n",
       "2   Hayley Matthews   WI    338\n",
       "3    Marizanne Kapp   SA    338\n",
       "4       Amelia Kerr   NZ    335\n",
       "5  Ashleigh Gardner  AUS    269\n",
       "6     Deepti Sharma  IND    249\n",
       "7     Jess Jonassen  AUS    245\n",
       "8         Sune Luus   SA    223\n",
       "9   Katherine Brunt  ENG    221"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques6. Program to scrape women's cricket ranking from icc-cricket.com\n",
    "# (iii) Top 10 ODI all rounder\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "aw=[]\n",
    "n=[]\n",
    "bw=[]\n",
    "t=[]\n",
    "cw=[]\n",
    "r=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    aw.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    n.append(i.text.replace('\\n',''))    \n",
    "\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    bw.append(i.text.replace('\\n','').split()[0])\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    t.append(i.text)    \n",
    "    \n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    cw.append(i.text) \n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    r.append(i.text)\n",
    "    \n",
    "rates=re[18:27]\n",
    "rates    \n",
    "    \n",
    "nam=aw[2]\n",
    "print(\"name[0]:\",nam)\n",
    "name=n[18:27]\n",
    "name.insert(0,'Natalie Sciver')\n",
    "tm=bw[1]\n",
    "print(\"teams[0]:\",tm)\n",
    "teams=t[18:27]\n",
    "teams.insert(0,'ENG')\n",
    "rt=cw[2]\n",
    "print(\"rate[0]:\",rt)\n",
    "rate=r[18:27]\n",
    "rate.insert(0,393)\n",
    "\n",
    "all_rounder = pd.DataFrame({\"Name\":name,\"team\":teams,\"Rating\":rate})\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8985c2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed’s Mester backs 75 basis point hike in July...</td>\n",
       "      <td>38 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/feds-mester-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treasury yields fall as traders track economic...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/treasury-yield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECB's Holzmann says there's ample room to hike...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/ecb-member-hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Russian terror' killing innocent civilians, U...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These are the most expensive places to work ab...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Incoming Philippines finance secretary wants t...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/incoming-phili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europe's plans to replace Russian gas are deem...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/europes-plans-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U.S. FCC commissioner wants Apple and Google t...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/fcc-commission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Israeli government collapse could mean a poten...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/israeli-govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECB's chief economist sees double-sided risk o...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/ecbs-lane-sees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>European markets pull back as investors weigh ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tesla is cutting about 200 Autopilot jobs and ...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/tesla-cutting-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Have stocks bottomed? Here’s one indicator pro...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/how-to-tell-if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Goldman sees 'rapid' growth in semiconductors ...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/goldman-sachs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hong Kong's Hang Seng briefly drops 2%; consum...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/asia-markets-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cramer's lightning round: I can't recommend Si...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AWS CEO says the move to cloud computing is on...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/aws-ceo-says-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U.S. to deploy nearly 300,000 monkeypox vaccin...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/us-to-deploy-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nike has a ‘much better risk-reward’ than the ...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/cramer-nike-ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jim Cramer picks 4 'buyable' stocks to snap up...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/jim-cramer-pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Stock futures fall slightly after failed attem...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/stock-market-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>China's economy didn't bounce back in the seco...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/chinas-economy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Best trades on CNBC Tuesday: Pros buy these st...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/best-trades-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Key takeaways from explosive Jan. 6 hearing fe...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/jan-6-hearing-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CVS removes purchase limit on Plan B pills, sa...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/cvs-to-remove-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FDA panel recommends changing Covid shots to f...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/fda-panel-reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Millions of US residents may get new stimulus ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/inflation-reli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>First phase of market downturn is done. Two mo...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/first-phase-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Disney extends CEO Bob Chapek's contract by th...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/disney-board-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pinterest CEO Ben Silbermann is stepping down ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/28/pinterest-shar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   Fed’s Mester backs 75 basis point hike in July...    38 Min Ago   \n",
       "1   Treasury yields fall as traders track economic...    1 Hour Ago   \n",
       "2   ECB's Holzmann says there's ample room to hike...    1 Hour Ago   \n",
       "3   'Russian terror' killing innocent civilians, U...   2 Hours Ago   \n",
       "4   These are the most expensive places to work ab...   3 Hours Ago   \n",
       "5   Incoming Philippines finance secretary wants t...   3 Hours Ago   \n",
       "6   Europe's plans to replace Russian gas are deem...   3 Hours Ago   \n",
       "7   U.S. FCC commissioner wants Apple and Google t...   3 Hours Ago   \n",
       "8   Israeli government collapse could mean a poten...   3 Hours Ago   \n",
       "9   ECB's chief economist sees double-sided risk o...   3 Hours Ago   \n",
       "10  European markets pull back as investors weigh ...   4 Hours Ago   \n",
       "11  Tesla is cutting about 200 Autopilot jobs and ...   7 Hours Ago   \n",
       "12  Have stocks bottomed? Here’s one indicator pro...   8 Hours Ago   \n",
       "13  Goldman sees 'rapid' growth in semiconductors ...   8 Hours Ago   \n",
       "14  Hong Kong's Hang Seng briefly drops 2%; consum...   9 Hours Ago   \n",
       "15  Cramer's lightning round: I can't recommend Si...   9 Hours Ago   \n",
       "16  AWS CEO says the move to cloud computing is on...   9 Hours Ago   \n",
       "17  U.S. to deploy nearly 300,000 monkeypox vaccin...  10 Hours Ago   \n",
       "18  Nike has a ‘much better risk-reward’ than the ...  10 Hours Ago   \n",
       "19  Jim Cramer picks 4 'buyable' stocks to snap up...  10 Hours Ago   \n",
       "20  Stock futures fall slightly after failed attem...  11 Hours Ago   \n",
       "21  China's economy didn't bounce back in the seco...  11 Hours Ago   \n",
       "22  Best trades on CNBC Tuesday: Pros buy these st...  11 Hours Ago   \n",
       "23  Key takeaways from explosive Jan. 6 hearing fe...  11 Hours Ago   \n",
       "24  CVS removes purchase limit on Plan B pills, sa...  12 Hours Ago   \n",
       "25  FDA panel recommends changing Covid shots to f...  12 Hours Ago   \n",
       "26  Millions of US residents may get new stimulus ...  12 Hours Ago   \n",
       "27  First phase of market downturn is done. Two mo...  12 Hours Ago   \n",
       "28  Disney extends CEO Bob Chapek's contract by th...  12 Hours Ago   \n",
       "29  Pinterest CEO Ben Silbermann is stepping down ...  12 Hours Ago   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/06/29/feds-mester-ba...  \n",
       "1   https://www.cnbc.com/2022/06/29/treasury-yield...  \n",
       "2   https://www.cnbc.com/2022/06/29/ecb-member-hol...  \n",
       "3   https://www.cnbc.com/2022/06/29/russia-ukraine...  \n",
       "4   https://www.cnbc.com/2022/06/29/these-are-the-...  \n",
       "5   https://www.cnbc.com/2022/06/29/incoming-phili...  \n",
       "6   https://www.cnbc.com/2022/06/29/europes-plans-...  \n",
       "7   https://www.cnbc.com/2022/06/29/fcc-commission...  \n",
       "8   https://www.cnbc.com/2022/06/29/israeli-govern...  \n",
       "9   https://www.cnbc.com/2022/06/29/ecbs-lane-sees...  \n",
       "10  https://www.cnbc.com/2022/06/29/european-marke...  \n",
       "11  https://www.cnbc.com/2022/06/28/tesla-cutting-...  \n",
       "12  https://www.cnbc.com/2022/06/29/how-to-tell-if...  \n",
       "13  https://www.cnbc.com/2022/06/29/goldman-sachs-...  \n",
       "14  https://www.cnbc.com/2022/06/29/asia-markets-w...  \n",
       "15  https://www.cnbc.com/2022/06/28/cramers-lightn...  \n",
       "16  https://www.cnbc.com/2022/06/28/aws-ceo-says-t...  \n",
       "17  https://www.cnbc.com/2022/06/28/us-to-deploy-n...  \n",
       "18  https://www.cnbc.com/2022/06/28/cramer-nike-ha...  \n",
       "19  https://www.cnbc.com/2022/06/28/jim-cramer-pic...  \n",
       "20  https://www.cnbc.com/2022/06/28/stock-market-f...  \n",
       "21  https://www.cnbc.com/2022/06/28/chinas-economy...  \n",
       "22  https://www.cnbc.com/2022/06/28/best-trades-on...  \n",
       "23  https://www.cnbc.com/2022/06/28/jan-6-hearing-...  \n",
       "24  https://www.cnbc.com/2022/06/28/cvs-to-remove-...  \n",
       "25  https://www.cnbc.com/2022/06/28/fda-panel-reco...  \n",
       "26  https://www.cnbc.com/2022/06/28/inflation-reli...  \n",
       "27  https://www.cnbc.com/2022/06/28/first-phase-of...  \n",
       "28  https://www.cnbc.com/2022/06/28/disney-board-v...  \n",
       "29  https://www.cnbc.com/2022/06/28/pinterest-shar...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques7. Python program to scrape mentioned news details \n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "headline = []\n",
    "time = []\n",
    "link = []\n",
    "\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "\n",
    "for i in soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)   \n",
    "\n",
    "for i in soup('a',class_=\"LatestNews-headline\"):\n",
    "    link.append(i.get(\"href\"))    \n",
    "    \n",
    "news = pd.DataFrame({\"Headline\":headline,\"Time\":time,\"News Link\":link})\n",
    "news   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e897c48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper url  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques8. Python program to scrape the details of most downloaded articles from AI in last 90 days\n",
    "\n",
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "paper=[]\n",
    "author=[]\n",
    "pub=[]\n",
    "url=[]\n",
    "\n",
    "for i in soup('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    paper.append(i.text)\n",
    "\n",
    "for i in soup('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "for i in soup('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    pub.append(i.text)\n",
    "\n",
    "for i in soup('a',class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    url.append(i.get(\"href\"))\n",
    "    \n",
    "article = pd.DataFrame({\"Paper Title\":paper,\"Authors\":author,\"Published Date\":pub,\"Paper url\":url})\n",
    "article    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b3cd065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>[North, Indian,, Chinese]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>[North, Indian,, Asian,, Italian]</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>[Chinese,, North, Indian]</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>[Italian,, Continental]</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>[North, Indian,, Chinese]</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>[North, Indian,, Italian]</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>[North, Indian,, Italian]</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>[North, Indian,, Mughlai]</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>[North, Indian,, Mughlai,, Desserts,, Beverages]</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>[European,, Italian,, Asian,, Continental]</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Restaurant name  \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3   Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4   The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad   \n",
       "11                          Barbeque 29NIT, Faridabad   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "0                          [North, Indian,, Chinese]   \n",
       "1                  [North, Indian,, Asian,, Italian]   \n",
       "2                          [Chinese,, North, Indian]   \n",
       "3                            [Italian,, Continental]   \n",
       "4                          [North, Indian,, Chinese]   \n",
       "5                          [North, Indian,, Italian]   \n",
       "6                                    [North, Indian]   \n",
       "7                                    [North, Indian]   \n",
       "8                          [North, Indian,, Italian]   \n",
       "9                          [North, Indian,, Mughlai]   \n",
       "10                                   [North, Indian]   \n",
       "11  [North, Indian,, Mughlai,, Desserts,, Beverages]   \n",
       "12        [European,, Italian,, Asian,, Continental]   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     3.5   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                  Gardens Galleria,Sector 38A, Noida       4   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.3   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     3.6   \n",
       "11                                     NIT, Faridabad     4.2   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...       4   \n",
       "\n",
       "                                            Image url  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques9. Python program to scrape details from dineout.co.in\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "titles = []\n",
    "titles1 = []\n",
    "titles2 = []\n",
    "titles3 = []\n",
    "image = []\n",
    "\n",
    "for i in soup.find_all('div',class_='restnt-info cursor'):\n",
    "    titles.append(i.text)\n",
    "\n",
    "    \n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    titles1.append(i.text.split()[6:])\n",
    "    \n",
    "\n",
    "for i in soup.find_all('div',class_='restnt-loc ellipsis'):\n",
    "    titles2.append(i.text)    \n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    titles3.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('img',class_='no-img'):\n",
    "    image.append(i['data-src'])\n",
    "    \n",
    "Restaurant = pd.DataFrame({\"Restaurant name\":titles,\"Cuisine\":titles1,\"Location\":titles2,\"Ratings\":titles3,\"Image url\":image})\n",
    "Restaurant    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b4fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques10. Python program to scrape the details of top publication \n",
    "\n",
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "rank = []\n",
    "pu = []\n",
    "h5 = []\n",
    "\n",
    "for i in soup('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "for i in soup('td',class_=\"gsc_mvt_t\"):\n",
    "    pu.append(i.text)    \n",
    "    \n",
    "for i in soup('td',class_=\"gsc_mvt_n\"):\n",
    "    h5.append(i.text)\n",
    "    \n",
    "index=h5[:202:2]\n",
    "median=h5[1:202:2]\n",
    "\n",
    "Top_publication = pd.DataFrame({\"Rank\":rank,\"Publication\":pu,\"h5-index\":index,\"h5-median\":median})\n",
    "Top_publication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
